{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "no_cuda = False\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grayscale은 안 되는 이유\n",
    "\n",
    "https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py#L157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.232911\n",
      "Train Epoch: 1 [200/60000 (0%)]\tLoss: 2.204920\n",
      "Train Epoch: 1 [400/60000 (1%)]\tLoss: 1.901318\n",
      "Train Epoch: 1 [600/60000 (1%)]\tLoss: 1.783645\n",
      "Train Epoch: 1 [800/60000 (1%)]\tLoss: 1.861633\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 1.308529\n",
      "Train Epoch: 1 [1200/60000 (2%)]\tLoss: 0.398948\n",
      "Train Epoch: 1 [1400/60000 (2%)]\tLoss: 0.448349\n",
      "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 0.500799\n",
      "Train Epoch: 1 [1800/60000 (3%)]\tLoss: 0.487348\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.096714\n",
      "Train Epoch: 1 [2200/60000 (4%)]\tLoss: 0.804104\n",
      "Train Epoch: 1 [2400/60000 (4%)]\tLoss: 0.181191\n",
      "Train Epoch: 1 [2600/60000 (4%)]\tLoss: 0.217457\n",
      "Train Epoch: 1 [2800/60000 (5%)]\tLoss: 0.034894\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.100181\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.260145\n",
      "Train Epoch: 1 [3400/60000 (6%)]\tLoss: 0.011204\n",
      "Train Epoch: 1 [3600/60000 (6%)]\tLoss: 0.010704\n",
      "Train Epoch: 1 [3800/60000 (6%)]\tLoss: 0.085857\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.006544\n",
      "Train Epoch: 1 [4200/60000 (7%)]\tLoss: 0.468256\n",
      "Train Epoch: 1 [4400/60000 (7%)]\tLoss: 0.092061\n",
      "Train Epoch: 1 [4600/60000 (8%)]\tLoss: 0.007170\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 0.086386\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.008531\n",
      "Train Epoch: 1 [5200/60000 (9%)]\tLoss: 0.045890\n",
      "Train Epoch: 1 [5400/60000 (9%)]\tLoss: 0.010391\n",
      "Train Epoch: 1 [5600/60000 (9%)]\tLoss: 0.171973\n",
      "Train Epoch: 1 [5800/60000 (10%)]\tLoss: 0.010529\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.911217\n",
      "Train Epoch: 1 [6200/60000 (10%)]\tLoss: 0.190894\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.284844\n",
      "Train Epoch: 1 [6600/60000 (11%)]\tLoss: 0.004608\n",
      "Train Epoch: 1 [6800/60000 (11%)]\tLoss: 0.030988\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.002042\n",
      "Train Epoch: 1 [7200/60000 (12%)]\tLoss: 0.594563\n",
      "Train Epoch: 1 [7400/60000 (12%)]\tLoss: 0.027013\n",
      "Train Epoch: 1 [7600/60000 (13%)]\tLoss: 0.009044\n",
      "Train Epoch: 1 [7800/60000 (13%)]\tLoss: 0.234935\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.000469\n",
      "Train Epoch: 1 [8200/60000 (14%)]\tLoss: 0.005757\n",
      "Train Epoch: 1 [8400/60000 (14%)]\tLoss: 0.021440\n",
      "Train Epoch: 1 [8600/60000 (14%)]\tLoss: 0.012102\n",
      "Train Epoch: 1 [8800/60000 (15%)]\tLoss: 2.327168\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.772761\n",
      "Train Epoch: 1 [9200/60000 (15%)]\tLoss: 0.004751\n",
      "Train Epoch: 1 [9400/60000 (16%)]\tLoss: 0.064552\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.006910\n",
      "Train Epoch: 1 [9800/60000 (16%)]\tLoss: 0.000601\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.146731\n",
      "Train Epoch: 1 [10200/60000 (17%)]\tLoss: 0.058498\n",
      "Train Epoch: 1 [10400/60000 (17%)]\tLoss: 0.046566\n",
      "Train Epoch: 1 [10600/60000 (18%)]\tLoss: 0.001207\n",
      "Train Epoch: 1 [10800/60000 (18%)]\tLoss: 0.019302\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.003549\n",
      "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.023783\n",
      "Train Epoch: 1 [11400/60000 (19%)]\tLoss: 0.178630\n",
      "Train Epoch: 1 [11600/60000 (19%)]\tLoss: 0.037193\n",
      "Train Epoch: 1 [11800/60000 (20%)]\tLoss: 0.020176\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.175030\n",
      "Train Epoch: 1 [12200/60000 (20%)]\tLoss: 0.003346\n",
      "Train Epoch: 1 [12400/60000 (21%)]\tLoss: 0.067472\n",
      "Train Epoch: 1 [12600/60000 (21%)]\tLoss: 0.005951\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.276975\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.008755\n",
      "Train Epoch: 1 [13200/60000 (22%)]\tLoss: 0.000861\n",
      "Train Epoch: 1 [13400/60000 (22%)]\tLoss: 0.001547\n",
      "Train Epoch: 1 [13600/60000 (23%)]\tLoss: 1.374528\n",
      "Train Epoch: 1 [13800/60000 (23%)]\tLoss: 0.340848\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.013831\n",
      "Train Epoch: 1 [14200/60000 (24%)]\tLoss: 0.022789\n",
      "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.000792\n",
      "Train Epoch: 1 [14600/60000 (24%)]\tLoss: 0.416799\n",
      "Train Epoch: 1 [14800/60000 (25%)]\tLoss: 0.410651\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.151646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-6ad95f9c7db1>\", line 10, in <module>\n",
      "    loss.backward()  # 계산한 기울기를\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\", line 118, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 93, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    # Train Mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()  # backpropagation 계산하기 전에 0으로 기울기 계산\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)  # https://pytorch.org/docs/stable/nn.html#nll-loss\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    # Test mode\n",
    "    model.eval()  # batch norm이나 dropout 등을 train mode 변환\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # autograd engine, 즉 backpropagatin이나 gradient 계산 등을 꺼서 memory usage를 줄이고 속도를 높임\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()  # pred와 target과 같은지 확인\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
